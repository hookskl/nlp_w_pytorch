{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_w_pytorch_cnn_surnames.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMb9Kx01KRObRa8C4z+B0LA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hookskl/nlp_w_pytorch/blob/main/nlp_w_pytorch_cnn_surnames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpfmn6cgTeKu",
        "outputId": "d67af600-7ff3-46e1-f531-261f9f7a5e50"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "# get python file shell script\r\n",
        "curl -o download.py https://raw.githubusercontent.com/hookskl/PyTorchNLPBook/master/data/download.py\r\n",
        "#! /bin/bash\r\n",
        "\r\n",
        "# For each file, add a download.py line\r\n",
        "# Any additional processing on the downloaded file\r\n",
        "\r\n",
        "HERE=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\r\n",
        "\r\n",
        "# Surnames Dataset\r\n",
        "mkdir -p $HERE/surnames\r\n",
        "if [ ! -f $HERE/surnames/surnames_with_splits.csv ]; then\r\n",
        "    python download.py 1T1la2tYO1O7XkMRawG8VcFcvtjbxDqU- $HERE/surnames/surnames_with_splits.csv # 8\r\n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1572  100  1572    0     0   9469      0 --:--:-- --:--:-- --:--:--  9469\n",
            "Trying to fetch /content/surnames/surnames_with_splits.csv\n",
            "8it [00:00, 2146.80it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTEWFj_WUEB1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TONJjBtEUBvf"
      },
      "source": [
        "from argparse import Namespace\r\n",
        "from collections import Counter\r\n",
        "import json\r\n",
        "import os\r\n",
        "import string\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-fhyUQFUJa4"
      },
      "source": [
        "## Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI7iqivOUQDB"
      },
      "source": [
        "class Vocabulary(object):\r\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\r\n",
        "            add_unk (bool): a flag that indicates whether to add the UNK token\r\n",
        "            unk_token (str): the UNK token to add into the Vocabulary\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        if token_to_idx is None:\r\n",
        "            token_to_idx = {}\r\n",
        "        self._token_to_idx = token_to_idx\r\n",
        "\r\n",
        "        self._idx_to_token = {idx: token\r\n",
        "                              for token, idx in self._token_to_idx.items()}\r\n",
        "\r\n",
        "        self._add_unk = add_unk\r\n",
        "        self._unk_token = unk_token\r\n",
        "\r\n",
        "        self.unk_index = -1\r\n",
        "        if add_unk:\r\n",
        "            self.unk_index = self.add_token(unk_token)\r\n",
        "\r\n",
        "    def to_serializable(self):\r\n",
        "        \"\"\"returns a dictionary that can be serialized\"\"\"\r\n",
        "        return {'token_to_idx': self._token_to_idx,\r\n",
        "                'add_unk': self._add_unk,\r\n",
        "                'unk_token': self._unk_token}\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_serializable(cls, contents):\r\n",
        "        \"\"\"instantiates the Vocabulary from a serialized dictionary\"\"\"\r\n",
        "        return cls(**contents)\r\n",
        "\r\n",
        "    def add_token(self, token):\r\n",
        "        \"\"\"Update mapping dicts based on the token.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            token (str): the item to add into the Vocabulary\r\n",
        "        Returns:\r\n",
        "            index (int): the integer corresponding to the token\r\n",
        "        \"\"\"\r\n",
        "        try:\r\n",
        "            index = self._token_to_idx[token]\r\n",
        "        except KeyError:\r\n",
        "            index = len(self._token_to_idx)\r\n",
        "            self._token_to_idx[token] = index \r\n",
        "            self._idx_to_token[index] = token\r\n",
        "        return index \r\n",
        "\r\n",
        "    def add_many(self, tokens):\r\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\r\n",
        "\r\n",
        "        Args:\r\n",
        "            tokens (list): a list of string tokens\r\n",
        "        Returns:\r\n",
        "            indices (list): a list of indices corresponding to the tokens\r\n",
        "        \"\"\"\r\n",
        "        return [self.add_token(token) for token in tokens]\r\n",
        "\r\n",
        "    def lookup_token(self, token):\r\n",
        "        \"\"\"Retrieve the index associated with the token\r\n",
        "          or the UNK the index if token isn't present.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            token (str): the token to look up \r\n",
        "        Returns:\r\n",
        "            index (int): the index corresponding to the token\r\n",
        "        Notes:\r\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary)\r\n",
        "              for the UNK functionality\r\n",
        "        \"\"\"\r\n",
        "        if self.unk_index >= 0:\r\n",
        "            return self._token_to_idx.get(token, self.unk_index)\r\n",
        "        else:\r\n",
        "            return self._token_to_idx[token]\r\n",
        "\r\n",
        "    def lookup_index(self, index):\r\n",
        "        \"\"\"Return the token associated with the index\r\n",
        "\r\n",
        "        Args:\r\n",
        "            index (int): the index to look up\r\n",
        "        Returns:\r\n",
        "            token (str): the token corresponding to the index\r\n",
        "        Raises:\r\n",
        "            KeyError: if the index is not in the Vocabulary\r\n",
        "        \"\"\"\r\n",
        "        if index not in self._idx_to_token:\r\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\r\n",
        "        return self._idx_to_token[index]\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJqV70yHUS28"
      },
      "source": [
        "## Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg5qJ8Q2UUs2"
      },
      "source": [
        "class SurnameVectorizer(object):\r\n",
        "    \"\"\"The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\r\n",
        "    def __init__(self, surname_vocab, nationality_vocab, max_surname_length):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            surname_vocab (Vocabulary): maps characters to integers\r\n",
        "            nationality_vocab (Vocabulary): maps nationalities to integers\r\n",
        "            max_surname_length (int): the length of the longest surname\r\n",
        "        \"\"\"\r\n",
        "        self.surname_vocab = surname_vocab\r\n",
        "        self.nationality_vocab = nationality_vocab\r\n",
        "        self._max_surname_length = max_surname_length\r\n",
        "\r\n",
        "    def vectorize(self, surname):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            surname (str): the surname\r\n",
        "        Returns:\r\n",
        "            one_hot_matrix (np.ndarray): a matrix of one-hot vectors\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        one_hot_matrix_size = (len(self.surname_vocab), self._max_surname_length)\r\n",
        "        one_hot_matrix = np.zeros(one_hot_matrix_size, dtype=np.float32)\r\n",
        "\r\n",
        "        for position_index, character in enumerate(surname):\r\n",
        "            character_index = self.surname_vocab.lookup_token(character)\r\n",
        "            one_hot_matrix[character_index][position_index] = 1\r\n",
        "\r\n",
        "        return one_hot_matrix\r\n",
        "\r\n",
        "    @classmethod \r\n",
        "    def from_dataframe(cls, surname_df):\r\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\r\n",
        "\r\n",
        "        Args:\r\n",
        "            surname_df (pandas.DataFrame): the surnames dataset\r\n",
        "        Returns:\r\n",
        "            an instance of the SurnameVectorizer\r\n",
        "        \"\"\"\r\n",
        "        surname_vocab = Vocabulary(unk_token=\"@\")\r\n",
        "        nationality_vocab = Vocabulary(add_unk=False)\r\n",
        "        max_surname_length = 0\r\n",
        "\r\n",
        "        for index, row in surname_df.iterrows():\r\n",
        "            max_surname_length = max(max_surname_length, len(row.surname))\r\n",
        "            for letter in row.surname:\r\n",
        "                surname_vocab.add_token(letter)\r\n",
        "            nationality_vocab.add_token(row.nationality)\r\n",
        "\r\n",
        "        return cls(surname_vocab, nationality_vocab, max_surname_length)\r\n",
        "\r\n",
        "    @classmethod \r\n",
        "    def from_serializable(cls, contents):\r\n",
        "        surname_vocab = Vocabulary.from_serializable(contents['surname_vocab'])\r\n",
        "        nationality_vocab = Vocabulary.from_serializable(contents['nationality_vocab'])\r\n",
        "        return cls(surname_vocab=surname_vocab, nationality_vocab=nationality_vocab, \r\n",
        "                   max_surname_length=contents['max_surname_length'])\r\n",
        "        \r\n",
        "    def to_serializable(self):\r\n",
        "        return {'surname_vocab': self.surname_vocab.to_serializable(),\r\n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable(),\r\n",
        "                'max_surname_length': self._max_surname_length}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1xFke06UVUk"
      },
      "source": [
        "## SurnameDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mByEhZ_VUXRL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24wcligYUax5"
      },
      "source": [
        "## Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5go6fv1Ucla"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHRz3pTVUdc0"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWuioITUUfFE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrd34m7oUgWL"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgJH7BOVVIYn"
      },
      "source": [
        "### Make Train State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lSbuO0cUg_P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70u8mU8KVMU0"
      },
      "source": [
        "### Update Train State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwR1N98yVNow"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZyEoK8qVP92"
      },
      "source": [
        "### Compute Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z65fay7VRvk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVxTYQelVSm3"
      },
      "source": [
        "### Define args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrRukx5pVUjD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWn7o9DgYYzY"
      },
      "source": [
        "### Instantiations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rigewRVOYcSJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuXXAOnuYftr"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfrhBuk_Yg3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubbOo7DpYiXP"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4VJVKZSYkad"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwjDKwa_kOO2"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lb_z7UVkQCe"
      },
      "source": [
        "### Predict Nationality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpM7uNuckPYy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4_9U8qvkTE1"
      },
      "source": [
        "### Predict Top k Nationality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQMT3cpMkWgA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}