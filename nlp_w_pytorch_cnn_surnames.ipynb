{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_w_pytorch_cnn_surnames.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQ3FLxfJjyTtrNxEE5Y61+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b2155547961749a7b47cb627dd827939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c121e5f46114722858f68c49e895133",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45cf6b52fa07477ea5f19b49d51192f1",
              "IPY_MODEL_6975527ee4b24bb4b7fc7bdb4cb15c5b"
            ]
          }
        },
        "6c121e5f46114722858f68c49e895133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45cf6b52fa07477ea5f19b49d51192f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d771bac20ecb41739843241db2c52337",
            "_dom_classes": [],
            "description": "training routine:   4%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90e5818521de45dc9a5ccd4e22fc6ac5"
          }
        },
        "6975527ee4b24bb4b7fc7bdb4cb15c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a72c26d9575f4debaa1c41c0592b224c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/100 [00:40&lt;16:02, 10.03s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9a0e08f85304c5483b6409fdaa871ce"
          }
        },
        "d771bac20ecb41739843241db2c52337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90e5818521de45dc9a5ccd4e22fc6ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a72c26d9575f4debaa1c41c0592b224c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9a0e08f85304c5483b6409fdaa871ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc1fe991729040408e8b49f5a9013dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_79767d355ef4452b84ffdcabd81d7cb6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f0bc9e5aec049709a5e33368dc2a3c1",
              "IPY_MODEL_1678b422621d46fdb46e0374d894db34"
            ]
          }
        },
        "79767d355ef4452b84ffdcabd81d7cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f0bc9e5aec049709a5e33368dc2a3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d060c2b29d1b4a16b53f6db364e8abbf",
            "_dom_classes": [],
            "description": "split=train:  87%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 60,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ab4ddaaa15a43d8af1df76c962c5fd5"
          }
        },
        "1678b422621d46fdb46e0374d894db34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11a9ccc4d90e4315b03211874bf95c1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 52/60 [00:48&lt;00:01,  6.49it/s, acc=64.2, epoch=4, loss=0.884]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89d619b12c754607ac71c9ff7c269763"
          }
        },
        "d060c2b29d1b4a16b53f6db364e8abbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ab4ddaaa15a43d8af1df76c962c5fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11a9ccc4d90e4315b03211874bf95c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89d619b12c754607ac71c9ff7c269763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29253c8442cd4c11b043cf0134502a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c43a2dae66534f62bcf12f64fc863106",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd2177b1f5c64936b2b02a20a73a56f0",
              "IPY_MODEL_d4e79bc4d70a4bb985631bf9dfe81de6"
            ]
          }
        },
        "c43a2dae66534f62bcf12f64fc863106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd2177b1f5c64936b2b02a20a73a56f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbcbb6bc315b47ffa3746b5a8f3791b5",
            "_dom_classes": [],
            "description": "split=val:  92%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 12,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f011524505174c2189a3c93faa934c25"
          }
        },
        "d4e79bc4d70a4bb985631bf9dfe81de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d375a39184941499eaf6cf80f566b2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/12 [00:40&lt;00:07,  7.18s/it, acc=53, epoch=3, loss=1.63]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d485e88950134181be52876b1312bf8e"
          }
        },
        "fbcbb6bc315b47ffa3746b5a8f3791b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f011524505174c2189a3c93faa934c25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d375a39184941499eaf6cf80f566b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d485e88950134181be52876b1312bf8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hookskl/nlp_w_pytorch/blob/main/nlp_w_pytorch_cnn_surnames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpfmn6cgTeKu",
        "outputId": "55eff44a-f6d5-4473-a40e-e292cf06364f"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "# get python file shell script\r\n",
        "curl -o download.py https://raw.githubusercontent.com/hookskl/PyTorchNLPBook/master/data/download.py\r\n",
        "#! /bin/bash\r\n",
        "\r\n",
        "# For each file, add a download.py line\r\n",
        "# Any additional processing on the downloaded file\r\n",
        "\r\n",
        "HERE=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\r\n",
        "\r\n",
        "# Surnames Dataset\r\n",
        "mkdir -p $HERE/surnames\r\n",
        "if [ ! -f $HERE/surnames/surnames_with_splits.csv ]; then\r\n",
        "    python download.py 1T1la2tYO1O7XkMRawG8VcFcvtjbxDqU- $HERE/surnames/surnames_with_splits.csv # 8\r\n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1572  100  1572    0     0  17863      0 --:--:-- --:--:-- --:--:-- 17863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTEWFj_WUEB1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TONJjBtEUBvf"
      },
      "source": [
        "from argparse import Namespace\r\n",
        "from collections import Counter\r\n",
        "import json\r\n",
        "import os\r\n",
        "import string\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-fhyUQFUJa4"
      },
      "source": [
        "## Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI7iqivOUQDB"
      },
      "source": [
        "class Vocabulary(object):\r\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\r\n",
        "            add_unk (bool): a flag that indicates whether to add the UNK token\r\n",
        "            unk_token (str): the UNK token to add into the Vocabulary\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        if token_to_idx is None:\r\n",
        "            token_to_idx = {}\r\n",
        "        self._token_to_idx = token_to_idx\r\n",
        "\r\n",
        "        self._idx_to_token = {idx: token\r\n",
        "                              for token, idx in self._token_to_idx.items()}\r\n",
        "\r\n",
        "        self._add_unk = add_unk\r\n",
        "        self._unk_token = unk_token\r\n",
        "\r\n",
        "        self.unk_index = -1\r\n",
        "        if add_unk:\r\n",
        "            self.unk_index = self.add_token(unk_token)\r\n",
        "\r\n",
        "    def to_serializable(self):\r\n",
        "        \"\"\"returns a dictionary that can be serialized\"\"\"\r\n",
        "        return {'token_to_idx': self._token_to_idx,\r\n",
        "                'add_unk': self._add_unk,\r\n",
        "                'unk_token': self._unk_token}\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_serializable(cls, contents):\r\n",
        "        \"\"\"instantiates the Vocabulary from a serialized dictionary\"\"\"\r\n",
        "        return cls(**contents)\r\n",
        "\r\n",
        "    def add_token(self, token):\r\n",
        "        \"\"\"Update mapping dicts based on the token.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            token (str): the item to add into the Vocabulary\r\n",
        "        Returns:\r\n",
        "            index (int): the integer corresponding to the token\r\n",
        "        \"\"\"\r\n",
        "        try:\r\n",
        "            index = self._token_to_idx[token]\r\n",
        "        except KeyError:\r\n",
        "            index = len(self._token_to_idx)\r\n",
        "            self._token_to_idx[token] = index \r\n",
        "            self._idx_to_token[index] = token\r\n",
        "        return index \r\n",
        "\r\n",
        "    def add_many(self, tokens):\r\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\r\n",
        "\r\n",
        "        Args:\r\n",
        "            tokens (list): a list of string tokens\r\n",
        "        Returns:\r\n",
        "            indices (list): a list of indices corresponding to the tokens\r\n",
        "        \"\"\"\r\n",
        "        return [self.add_token(token) for token in tokens]\r\n",
        "\r\n",
        "    def lookup_token(self, token):\r\n",
        "        \"\"\"Retrieve the index associated with the token\r\n",
        "          or the UNK the index if token isn't present.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            token (str): the token to look up \r\n",
        "        Returns:\r\n",
        "            index (int): the index corresponding to the token\r\n",
        "        Notes:\r\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary)\r\n",
        "              for the UNK functionality\r\n",
        "        \"\"\"\r\n",
        "        if self.unk_index >= 0:\r\n",
        "            return self._token_to_idx.get(token, self.unk_index)\r\n",
        "        else:\r\n",
        "            return self._token_to_idx[token]\r\n",
        "\r\n",
        "    def lookup_index(self, index):\r\n",
        "        \"\"\"Return the token associated with the index\r\n",
        "\r\n",
        "        Args:\r\n",
        "            index (int): the index to look up\r\n",
        "        Returns:\r\n",
        "            token (str): the token corresponding to the index\r\n",
        "        Raises:\r\n",
        "            KeyError: if the index is not in the Vocabulary\r\n",
        "        \"\"\"\r\n",
        "        if index not in self._idx_to_token:\r\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\r\n",
        "        return self._idx_to_token[index]\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJqV70yHUS28"
      },
      "source": [
        "## Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg5qJ8Q2UUs2"
      },
      "source": [
        "class SurnameVectorizer(object):\r\n",
        "    \"\"\"The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\r\n",
        "    def __init__(self, surname_vocab, nationality_vocab, max_surname_length):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            surname_vocab (Vocabulary): maps characters to integers\r\n",
        "            nationality_vocab (Vocabulary): maps nationalities to integers\r\n",
        "            max_surname_length (int): the length of the longest surname\r\n",
        "        \"\"\"\r\n",
        "        self.surname_vocab = surname_vocab\r\n",
        "        self.nationality_vocab = nationality_vocab\r\n",
        "        self._max_surname_length = max_surname_length\r\n",
        "\r\n",
        "    def vectorize(self, surname):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            surname (str): the surname\r\n",
        "        Returns:\r\n",
        "            one_hot_matrix (np.ndarray): a matrix of one-hot vectors\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        one_hot_matrix_size = (len(self.surname_vocab), self._max_surname_length)\r\n",
        "        one_hot_matrix = np.zeros(one_hot_matrix_size, dtype=np.float32)\r\n",
        "\r\n",
        "        for position_index, character in enumerate(surname):\r\n",
        "            character_index = self.surname_vocab.lookup_token(character)\r\n",
        "            one_hot_matrix[character_index][position_index] = 1\r\n",
        "\r\n",
        "        return one_hot_matrix\r\n",
        "\r\n",
        "    @classmethod \r\n",
        "    def from_dataframe(cls, surname_df):\r\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\r\n",
        "\r\n",
        "        Args:\r\n",
        "            surname_df (pandas.DataFrame): the surnames dataset\r\n",
        "        Returns:\r\n",
        "            an instance of the SurnameVectorizer\r\n",
        "        \"\"\"\r\n",
        "        surname_vocab = Vocabulary(unk_token=\"@\")\r\n",
        "        nationality_vocab = Vocabulary(add_unk=False)\r\n",
        "        max_surname_length = 0\r\n",
        "\r\n",
        "        for index, row in surname_df.iterrows():\r\n",
        "            max_surname_length = max(max_surname_length, len(row.surname))\r\n",
        "            for letter in row.surname:\r\n",
        "                surname_vocab.add_token(letter)\r\n",
        "            nationality_vocab.add_token(row.nationality)\r\n",
        "\r\n",
        "        return cls(surname_vocab, nationality_vocab, max_surname_length)\r\n",
        "\r\n",
        "    @classmethod \r\n",
        "    def from_serializable(cls, contents):\r\n",
        "        surname_vocab = Vocabulary.from_serializable(contents['surname_vocab'])\r\n",
        "        nationality_vocab = Vocabulary.from_serializable(contents['nationality_vocab'])\r\n",
        "        return cls(surname_vocab=surname_vocab, nationality_vocab=nationality_vocab, \r\n",
        "                   max_surname_length=contents['max_surname_length'])\r\n",
        "        \r\n",
        "    def to_serializable(self):\r\n",
        "        return {'surname_vocab': self.surname_vocab.to_serializable(),\r\n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable(),\r\n",
        "                'max_surname_length': self._max_surname_length}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1xFke06UVUk"
      },
      "source": [
        "## SurnameDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mByEhZ_VUXRL"
      },
      "source": [
        "class SurnameDataset(Dataset):\r\n",
        "    def __init__(self, surname_df, vectorizer):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            surname_df: (pandas.DataFrame): the dataset\r\n",
        "            vectorizer (SurnameVectorizer): vectorizer instantiated from dataset\r\n",
        "        \"\"\"\r\n",
        "        self.surname_df = surname_df\r\n",
        "        self._vectorizer = vectorizer\r\n",
        "\r\n",
        "        self.train_df = self.surname_df[self.surname_df.split=='train']\r\n",
        "        self.train_size = len(self.train_df)\r\n",
        "\r\n",
        "        self.val_df = self.surname_df[self.surname_df.split=='val']\r\n",
        "        self.validation_size = len(self.val_df)\r\n",
        "\r\n",
        "        self.test_df = self.surname_df[self.surname_df.split=='test']\r\n",
        "        self.test_size = len(self.test_df)\r\n",
        "\r\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\r\n",
        "                             'val': (self.val_df, self.validation_size),\r\n",
        "                             'test': (self.test_df, self.test_size)}\r\n",
        "\r\n",
        "        self.set_split('train')\r\n",
        "\r\n",
        "        # Class weights\r\n",
        "        class_counts = surname_df.nationality.value_counts().to_dict()\r\n",
        "        def sort_key(item):\r\n",
        "            return self._vectorizer.nationality_vocab.lookup_token(item[0])\r\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\r\n",
        "        frequencies = [count for _, count in sorted_counts]\r\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def load_dataset_and_make_vectorizer(cls, surname_csv):\r\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\r\n",
        "\r\n",
        "        Args:\r\n",
        "            surname_csv (str): location of the dataset\r\n",
        "        Returns:\r\n",
        "            an instance of SurnameDataset\r\n",
        "        \"\"\"\r\n",
        "        surname_df = pd.read_csv(surname_csv)\r\n",
        "        train_surname_df = surname_df[surname_df.split=='train']\r\n",
        "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def load_dataset_and_load_vectorizer(cls, surname_csv, vectorizer_filepath):\r\n",
        "        \"\"\"Load dataset and the corresponding vectorizer.\r\n",
        "        Used in the case in the vectorizer has been cached for re-use\r\n",
        "\r\n",
        "        Args:\r\n",
        "            surname_csv (str): location of the dataset\r\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\r\n",
        "        Returns:\r\n",
        "            an instance of SurnameDataset\r\n",
        "        \"\"\"\r\n",
        "        surname_df = pd.read_csv(surname_csv)\r\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\r\n",
        "        return cls(surname_df, vectorizer)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def load_vectorizer_only(vectorizer_filepath):\r\n",
        "        \"\"\"a static method for loading the vectorizer from file\r\n",
        "\r\n",
        "        Args:\r\n",
        "            vectorizer_filepath (str): the location the serialized vectorizer\r\n",
        "        Returns:\r\n",
        "            an instance of the SurnameDataset\r\n",
        "        \"\"\"\r\n",
        "        with open(vectorizer_filepath) as fp:\r\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\r\n",
        "\r\n",
        "    def save_vectorizer(self, vectorizer_filepath):\r\n",
        "        \"\"\"saves the vectorizer to disk using json\r\n",
        "\r\n",
        "        Args:\r\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\r\n",
        "        \"\"\"\r\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\r\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\r\n",
        "\r\n",
        "    def get_vectorizer(self):\r\n",
        "        \"\"\"returns the vectorizer\"\"\"\r\n",
        "        return self._vectorizer \r\n",
        "\r\n",
        "    def set_split(self, split=\"train\"):\r\n",
        "        \"\"\"selects the splits in the dataset using the column in the dataframe\"\"\"\r\n",
        "        self._target_split = split\r\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self._target_size \r\n",
        "    \r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\r\n",
        "\r\n",
        "        Args:\r\n",
        "            index (int): the index to the data point\r\n",
        "        Returns:\r\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\r\n",
        "        \"\"\"\r\n",
        "        row = self._target_df.iloc[index]\r\n",
        "\r\n",
        "        surname_matrix = \\\r\n",
        "            self._vectorizer.vectorize(row.surname)\r\n",
        "\r\n",
        "        nationality_index = \\\r\n",
        "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\r\n",
        "\r\n",
        "        return {'x_surname': surname_matrix, \r\n",
        "                'y_nationality': nationality_index}\r\n",
        "\r\n",
        "    def get_num_batches(self, batch_size):\r\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\r\n",
        "\r\n",
        "        Args:\r\n",
        "            batch_size (int)\r\n",
        "        Returns:\r\n",
        "            number of batches in the dataset\r\n",
        "        \"\"\"\r\n",
        "        return len(self) // batch_size \r\n",
        "      \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24wcligYUax5"
      },
      "source": [
        "## Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5go6fv1Ucla"
      },
      "source": [
        "def generate_batches(dataset, batch_size, shuffle=True,\r\n",
        "                     drop_last=True, device=\"cpu\"):\r\n",
        "    \"\"\"\r\n",
        "    A generator function which wraps the PyTorch DataLoader. It will\r\n",
        "      ensure each tensor is on the right device location.\r\n",
        "    \"\"\"\r\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\r\n",
        "                            shuffle=shuffle, drop_last=drop_last)\r\n",
        "    \r\n",
        "    for data_dict in dataloader:\r\n",
        "        out_data_dict = {}\r\n",
        "        for name, tensor in data_dict.items():\r\n",
        "            out_data_dict[name] = data_dict[name].to(device)\r\n",
        "        yield out_data_dict"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHRz3pTVUdc0"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWuioITUUfFE"
      },
      "source": [
        "class SurnameClassifier(nn.Module):\r\n",
        "    def __init__(self, initial_num_channels, num_classes, num_channels):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            initial_num_channels (int): size of the incoming feature vector\r\n",
        "            num_classes (int): size of the output prediction vector\r\n",
        "            num_channels (int): constant channel size to use throughout network\r\n",
        "        \"\"\"\r\n",
        "        super(SurnameClassifier, self).__init__()\r\n",
        "\r\n",
        "        self.convnet = nn.Sequential(\r\n",
        "            nn.Conv1d(in_channels=initial_num_channels,\r\n",
        "                      out_channels=num_channels, kernel_size=3),\r\n",
        "            nn.ELU(),\r\n",
        "            nn.BatchNorm1d(num_features=num_channels),\r\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\r\n",
        "                      kernel_size=3, stride=2),\r\n",
        "            nn.ELU(),\r\n",
        "            nn.BatchNorm1d(num_features=num_channels),\r\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\r\n",
        "                      kernel_size=3, stride=2),\r\n",
        "            nn.ELU(),\r\n",
        "            nn.BatchNorm1d(num_features=num_channels),\r\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\r\n",
        "                      kernel_size=3),\r\n",
        "            nn.ELU(),\r\n",
        "            nn.BatchNorm1d(num_features=num_channels)\r\n",
        "        )\r\n",
        "        \r\n",
        "        self.fc1 = nn.Linear(num_channels, 128)\r\n",
        "        self.fc2 = nn.Linear(128, num_classes)\r\n",
        "\r\n",
        "    def forward(self, x_surname, apply_softmax=False):\r\n",
        "        \"\"\"The forward pass of the classifier\r\n",
        "\r\n",
        "        Args:\r\n",
        "            x_surname (torch.Tensor): an input data tensor\r\n",
        "              x_surname.shape should be (batch, initial_num_channels, max_surname_length)\r\n",
        "            apply_softmax(bool): a flag for the softmax activation\r\n",
        "        Returns:\r\n",
        "            the resulting tensor.\r\n",
        "              tensor.shape should be (batch, num_classes)\r\n",
        "        \"\"\"\r\n",
        "        features = self.convnet(x_surname).squeeze(dim=2)\r\n",
        "        x = F.relu(self.fc1(features))\r\n",
        "        prediction_vector  = F.relu(self.fc2(x))\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "        if apply_softmax:\r\n",
        "            prediction_vector = F.softmax(prediction_vector, dim=1)\r\n",
        "\r\n",
        "        return prediction_vector"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrd34m7oUgWL"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgJH7BOVVIYn"
      },
      "source": [
        "### Make Train State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lSbuO0cUg_P"
      },
      "source": [
        "def make_train_state(args):\r\n",
        "    return {'stop_early': False,\r\n",
        "            'early_stopping_step': 0,\r\n",
        "            'early_stopping_best_val': 1e8,\r\n",
        "            'learning_rate': args.learning_rate,\r\n",
        "            'epoch_index': 0,\r\n",
        "            'train_loss': [],\r\n",
        "            'train_acc': [],\r\n",
        "            'val_loss': [],\r\n",
        "            'val_acc': [],\r\n",
        "            'test_loss': -1,\r\n",
        "            'test_acc': -1,\r\n",
        "            'model_filename': args.model_state_file}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70u8mU8KVMU0"
      },
      "source": [
        "### Update Train State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwR1N98yVNow"
      },
      "source": [
        "def update_train_state(args, model, train_state):\r\n",
        "    \"\"\"Handle the training state updates.\r\n",
        "\r\n",
        "    Components:\r\n",
        "     - Early Stopping: Prevent overfitting.\r\n",
        "     - Model Checkpoint: Model is saved if the model is better\r\n",
        "\r\n",
        "    :param args: main arguments\r\n",
        "    :param model: model to train\r\n",
        "    :param train_state: a dictionary representing the training state values\r\n",
        "    :returns:\r\n",
        "        a new train_state\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Save one model at least\r\n",
        "    if train_state['epoch_index'] == 0:\r\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\r\n",
        "        train_state['stop_early'] = False\r\n",
        "\r\n",
        "    # Save model if performance improved\r\n",
        "    elif train_state['epoch_index'] >= 1:\r\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\r\n",
        "\r\n",
        "        # If loss worsened\r\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\r\n",
        "            # Update step\r\n",
        "            train_state['early_stopping_step'] += 1\r\n",
        "        # Loss decreased\r\n",
        "        else:\r\n",
        "            # Save the best model\r\n",
        "            if loss_t < train_state['early_stopping_best_val']:\r\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\r\n",
        "\r\n",
        "            # Reset early stopping step\r\n",
        "            train_state['early_stopping_step'] = 0\r\n",
        "\r\n",
        "        # Stop early ?\r\n",
        "        train_state['stop_early'] = \\\r\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\r\n",
        "\r\n",
        "    return train_state"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZyEoK8qVP92"
      },
      "source": [
        "### Compute Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z65fay7VRvk"
      },
      "source": [
        "def compute_accuracy(y_pred, y_target):\r\n",
        "    y_pred_indices = y_pred.max(dim=1)[1]\r\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\r\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVxTYQelVSm3"
      },
      "source": [
        "### Define args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrRukx5pVUjD",
        "outputId": "0e3fe40e-7928-4ee8-f6a1-9aada8918211"
      },
      "source": [
        "args = Namespace(\r\n",
        "    # Data and Path information\r\n",
        "    surname_csv=\"surnames/surnames_with_splits.csv\",\r\n",
        "    vectorizer_file=\"vectorizer.json\",\r\n",
        "    model_state_file=\"model.pth\",\r\n",
        "    save_dir=\"model_storage/ch4/cnn\",\r\n",
        "    # Model hyper parameters\r\n",
        "    hidden_dim=100,\r\n",
        "    num_channels=256,\r\n",
        "    # Training hyper parameters\r\n",
        "    seed=1337,\r\n",
        "    learning_rate=0.001,\r\n",
        "    batch_size=128,\r\n",
        "    num_epochs=100,\r\n",
        "    early_stopping_criteria=5,\r\n",
        "    dropout_p=0.1,\r\n",
        "    # Runtime options\r\n",
        "    cuda=False,\r\n",
        "    reload_from_files=False,\r\n",
        "    expand_filepaths_to_save_dir=True,\r\n",
        "    catch_keyboard_interrupt=True\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "if args.expand_filepaths_to_save_dir:\r\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\r\n",
        "                                        args.vectorizer_file)\r\n",
        "\r\n",
        "    args.model_state_file = os.path.join(args.save_dir,\r\n",
        "                                         args.model_state_file)\r\n",
        "    \r\n",
        "    print(\"Expanded filepaths: \")\r\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\r\n",
        "    print(\"\\t{}\".format(args.model_state_file))\r\n",
        "    \r\n",
        "# Check CUDA\r\n",
        "if not torch.cuda.is_available():\r\n",
        "    args.cuda = False\r\n",
        "\r\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\r\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\r\n",
        "\r\n",
        "def set_seed_everywhere(seed, cuda):\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    if cuda:\r\n",
        "        torch.cuda.manual_seed_all(seed)\r\n",
        "        \r\n",
        "def handle_dirs(dirpath):\r\n",
        "    if not os.path.exists(dirpath):\r\n",
        "        os.makedirs(dirpath)\r\n",
        "        \r\n",
        "# Set seed for reproducibility\r\n",
        "set_seed_everywhere(args.seed, args.cuda)\r\n",
        "\r\n",
        "# handle dirs\r\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tmodel_storage/ch4/cnn/vectorizer.json\n",
            "\tmodel_storage/ch4/cnn/model.pth\n",
            "Using CUDA: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWn7o9DgYYzY"
      },
      "source": [
        "### Instantiations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwcG4KeKFAHF"
      },
      "source": [
        "if args.reload_from_files:\r\n",
        "    # training from a checkpoint\r\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\r\n",
        "                                                              args.vectorizer_file)\r\n",
        "else:\r\n",
        "    # create dataset and vectorizer\r\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\r\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\r\n",
        "\r\n",
        "vectorizer = dataset.get_vectorizer()\r\n",
        "\r\n",
        "classifier = SurnameClassifier(initial_num_channels=len(vectorizer.surname_vocab),\r\n",
        "                               num_classes=len(vectorizer.nationality_vocab),\r\n",
        "                               num_channels=args.num_channels)\r\n",
        "\r\n",
        "classifier = classifier.to(args.device)\r\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\r\n",
        "\r\n",
        "loss_func = nn.CrossEntropyLoss(weight=dataset.class_weights)\r\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\r\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\r\n",
        "                                                 mode='min', factor=0.5,\r\n",
        "                                                 patience=1)\r\n",
        "\r\n",
        "train_state = make_train_state(args)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuXXAOnuYftr"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "b2155547961749a7b47cb627dd827939",
            "6c121e5f46114722858f68c49e895133",
            "45cf6b52fa07477ea5f19b49d51192f1",
            "6975527ee4b24bb4b7fc7bdb4cb15c5b",
            "d771bac20ecb41739843241db2c52337",
            "90e5818521de45dc9a5ccd4e22fc6ac5",
            "a72c26d9575f4debaa1c41c0592b224c",
            "a9a0e08f85304c5483b6409fdaa871ce",
            "cc1fe991729040408e8b49f5a9013dea",
            "79767d355ef4452b84ffdcabd81d7cb6",
            "8f0bc9e5aec049709a5e33368dc2a3c1",
            "1678b422621d46fdb46e0374d894db34",
            "d060c2b29d1b4a16b53f6db364e8abbf",
            "6ab4ddaaa15a43d8af1df76c962c5fd5",
            "11a9ccc4d90e4315b03211874bf95c1e",
            "89d619b12c754607ac71c9ff7c269763",
            "29253c8442cd4c11b043cf0134502a29",
            "c43a2dae66534f62bcf12f64fc863106",
            "dd2177b1f5c64936b2b02a20a73a56f0",
            "d4e79bc4d70a4bb985631bf9dfe81de6",
            "fbcbb6bc315b47ffa3746b5a8f3791b5",
            "f011524505174c2189a3c93faa934c25",
            "9d375a39184941499eaf6cf80f566b2f",
            "d485e88950134181be52876b1312bf8e"
          ]
        },
        "id": "OfrhBuk_Yg3Q",
        "outputId": "e8a541e7-c9fa-40f0-e9ec-5cebc3ee32fb"
      },
      "source": [
        "# progress bars for training and validation sets\r\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \r\n",
        "                          total=args.num_epochs,\r\n",
        "                          position=0)\r\n",
        "\r\n",
        "dataset.set_split('train')\r\n",
        "train_bar = tqdm_notebook(desc='split=train',\r\n",
        "                          total=dataset.get_num_batches(args.batch_size), \r\n",
        "                          position=1, \r\n",
        "                          leave=True)\r\n",
        "dataset.set_split('val')\r\n",
        "val_bar = tqdm_notebook(desc='split=val',\r\n",
        "                        total=dataset.get_num_batches(args.batch_size), \r\n",
        "                        position=1, \r\n",
        "                        leave=True)\r\n",
        "\r\n",
        "try:\r\n",
        "    for epoch_index in range(args.num_epochs):\r\n",
        "        train_state['epoch_index'] = epoch_index \r\n",
        "\r\n",
        "        # Iterate over training dataset\r\n",
        "\r\n",
        "        # setup: batch generator, set loss and acc to 0.0, set train mode on\r\n",
        "\r\n",
        "        dataset.set_split('train')\r\n",
        "        batch_generator = generate_batches(dataset,\r\n",
        "                                           batch_size=args.batch_size,\r\n",
        "                                           device=args.device)\r\n",
        "        \r\n",
        "        running_loss = 0.0\r\n",
        "        running_acc = 0.0\r\n",
        "        classifier.train()\r\n",
        "\r\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "            # the training routine \r\n",
        "\r\n",
        "            # ---------------------------------------\r\n",
        "            # step 1. zero the gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # step 2. compute the output\r\n",
        "            y_pred = classifier(batch_dict['x_surname'])\r\n",
        "\r\n",
        "            # step 3. compute the loss\r\n",
        "            loss = loss_func(y_pred, batch_dict['y_nationality'])\r\n",
        "            loss_t = loss.item()\r\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "            # step 4. use loss to produce gradients\r\n",
        "            loss.backward()\r\n",
        "\r\n",
        "            # step 5. use optimizer to update model weights\r\n",
        "            optimizer.step()\r\n",
        "            # ---------------------------------------\r\n",
        "            # compute the accuracy\r\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\r\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "\r\n",
        "            # update bar\r\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc,\r\n",
        "                                  epoch=epoch_index)\r\n",
        "            train_bar.update()\r\n",
        "\r\n",
        "        train_state['train_loss'].append(running_loss)\r\n",
        "        train_state['train_acc'].append(running_acc)\r\n",
        "\r\n",
        "        # Iterate over val dataset\r\n",
        "\r\n",
        "        # setup: batch generator, set loss and acc to 0.0, set eval mode on\r\n",
        "        dataset.set_split('val')\r\n",
        "        batch_generator = generate_batches(dataset,\r\n",
        "                                           batch_size=args.batch_size,\r\n",
        "                                           device=args.device)\r\n",
        "        \r\n",
        "        running_loss = 0.0\r\n",
        "        running_acc = 0.0\r\n",
        "        classifier.eval()\r\n",
        "\r\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "\r\n",
        "            # compute the output\r\n",
        "            y_pred = classifier(batch_dict['x_surname'])\r\n",
        "\r\n",
        "            # compute the loss\r\n",
        "            loss = loss_func(y_pred, batch_dict['y_nationality'])\r\n",
        "            loss_t = loss.item()\r\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "            # compute the accuracy\r\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\r\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc,\r\n",
        "                                epoch=epoch_index)\r\n",
        "            val_bar.update()\r\n",
        "\r\n",
        "        train_state['val_loss'].append(running_loss)\r\n",
        "        train_state['val_acc'].append(running_acc)\r\n",
        "\r\n",
        "        train_state = update_train_state(args=args, model=classifier,\r\n",
        "                                         train_state=train_state)\r\n",
        "        scheduler.step(train_state['val_loss'][-1])\r\n",
        "\r\n",
        "        if train_state['stop_early']:\r\n",
        "            break\r\n",
        "\r\n",
        "        train_bar.n = 0\r\n",
        "        val_bar.n = 0\r\n",
        "        epoch_bar.update()\r\n",
        "except KeyboardInterrupt:\r\n",
        "    print(\"Exiting loop\")\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2155547961749a7b47cb627dd827939",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc1fe991729040408e8b49f5a9013dea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=train', max=60.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29253c8442cd4c11b043cf0134502a29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=val', max=12.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Exiting loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubbOo7DpYiXP"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4VJVKZSYkad"
      },
      "source": [
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\r\n",
        "\r\n",
        "classifier = classifier.to(args.device)\r\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\r\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\r\n",
        "\r\n",
        "dataset.set_split('test')\r\n",
        "batch_generator = generate_batches(dataset, \r\n",
        "                                   batch_size=args.batch_size, \r\n",
        "                                   device=args.device)\r\n",
        "running_loss = 0.\r\n",
        "running_acc = 0.\r\n",
        "classifier.eval()\r\n",
        "\r\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "    # compute the output\r\n",
        "    y_pred =  classifier(batch_dict['x_surname'])\r\n",
        "    \r\n",
        "    # compute the loss\r\n",
        "    loss = loss_func(y_pred, batch_dict['y_nationality'])\r\n",
        "    loss_t = loss.item()\r\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "    # compute the accuracy\r\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\r\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "\r\n",
        "train_state['test_loss'] = running_loss\r\n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSaIGJTrOgrb",
        "outputId": "c6bf0c77-139c-4cdd-8d37-9611b7bf8fc3"
      },
      "source": [
        "print(\"Test loss: {};\".format(train_state['test_loss']))\r\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.5678517917792;\n",
            "Test Accuracy: 52.278645833333336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwjDKwa_kOO2"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lb_z7UVkQCe"
      },
      "source": [
        "### Predict Nationality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpM7uNuckPYy"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4_9U8qvkTE1"
      },
      "source": [
        "### Predict Top k Nationality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQMT3cpMkWgA"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}