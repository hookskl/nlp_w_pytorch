{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_w_pytorch_ch5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGWo0OzTl6zgOU+9VvDA8t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hookskl/nlp_w_pytorch/blob/main/nlp_w_pytorch_ch5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdRDG3KL5S3a"
      },
      "source": [
        "# Embedding Words and Types\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu00Qwau5_f3"
      },
      "source": [
        "## Why Learn Embeddings?\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZlELToI6Ciy"
      },
      "source": [
        "### Efficiency of Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONHfkXR16Hk7"
      },
      "source": [
        "### Approaches to Learning Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G93wPQaf6LjI"
      },
      "source": [
        "### The Practical Use of Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRo30C146Q85"
      },
      "source": [
        "#### Loading Embeddings\r\n",
        "\r\n",
        "*Example 5-1. Using pretrained word embeddings*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQVBs-g45PPX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzl7SGGv7oiv"
      },
      "source": [
        "#### Relationships between word embeddings\r\n",
        "\r\n",
        "*Example 5-2. The analogy task using word embeddings*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYH-xFL-74Uk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLPW7un_771z"
      },
      "source": [
        "*Example 5-3. Word embeddings encode many linguistics relationships, as illustrated using the SAT analogy task*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y9WJurB8DdX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TRtOACU8HsB"
      },
      "source": [
        "*5-4. An example illustrating the danger of using cooccurrences to encode meaning---sometimes they do not!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Ufl4Ag8Tbs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-q3MKxT8dsx"
      },
      "source": [
        "*Example 5-5. Watch out for protected attributes such as gender encoded in word embeddings. This can introduce unwanted biases in downstream models.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tynKBZs68mGb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdtzusZI8q4w"
      },
      "source": [
        "*Example 5-6. Cultural gender bias encoded in vector analogy*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbf8daZu8v2_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHRwKBAa8zfa"
      },
      "source": [
        "## Exampled: Learning the Continuous Bag of Words Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGHNOrJn836G"
      },
      "source": [
        "### The Frankenstein Dataset\r\n",
        "\r\n",
        "*Example 5-7. Constructing a dataset class for the CBOW task*\r\n",
        "\r\n",
        "```\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GROVOvUG9FmY"
      },
      "source": [
        "### Vocabularly, Vectorizer, DataLoader\r\n",
        "\r\n",
        "*Exampled 5-8. A Vectorizer for the CBOW data*\r\n",
        "\r\n",
        "```\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOWlBD2k9Q0H"
      },
      "source": [
        "### The CBOWClassifier Model\r\n",
        "\r\n",
        "*Example 5-9. The CBOWClassifier model*\r\n",
        "\r\n",
        "```\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cITb29y39X_N"
      },
      "source": [
        "### The Training Routine\r\n",
        "\r\n",
        "*Example 5-10. Arguments to the CBOW training script*\r\n",
        "\r\n",
        "```\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvFE6dvk-EeD"
      },
      "source": [
        "### Model Evaluation and Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk-tU26U-HWe"
      },
      "source": [
        "## Example: Transfer Learning Using Pretrained Embeddings for Document Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MQQgJwJ-pAm"
      },
      "source": [
        "### The AG News Dataset\r\n",
        "\r\n",
        "*Example 5-11. The NewsDataset.__getitem__() method*\r\n",
        "\r\n",
        "```\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAPLV_N9_PyE"
      },
      "source": [
        "### Vocabulary, Vectorizer, and DataLoader\r\n",
        "\r\n",
        "*Exampled 5-12. Implementing a Vectorizer for the AG News dataset*\r\n",
        "\r\n",
        "```\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqGGRIPP_Z_3"
      },
      "source": [
        "### The NewsClassifier Model\r\n",
        "\r\n",
        "*Example 5-13. Selecting a subset of the word embeddings based on the vocabulary*\r\n",
        "\r\n",
        "```\r\n",
        "```\r\n",
        "\r\n",
        "*Example 5-14. Implementing the NewsClassifier*\r\n",
        "\r\n",
        "```\r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xxRd0IAALMM"
      },
      "source": [
        "### The Training Routine\r\n",
        "\r\n",
        "*Example 5-15. Arguments to the CNN NewsClassifier using pretrained embeddings*\r\n",
        "\r\n",
        "```\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAdlrfokAT8P"
      },
      "source": [
        "### Model Evaluation and Prediction\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd2ZVbJSAXP-"
      },
      "source": [
        "#### Evaluating on the test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT10jwLDAZsh"
      },
      "source": [
        "#### Predicting the category of novel news headlines\r\n",
        "\r\n",
        "*Example 5-16. Predicting with the trained model*\r\n",
        "\r\n",
        "```\r\n",
        "```"
      ]
    }
  ]
}