{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_w_pytorch_ch7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXS6lpi+M174M0h7RtEk37",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hookskl/nlp_w_pytorch/blob/main/nlp_w_pytorch_ch7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6W6cw-7MGTw"
      },
      "source": [
        "# Intermediate Sequence Modeling for NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2-7db3cMSn0"
      },
      "source": [
        "## The Problem with Vanilla RNNs (Elman RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9fBEOYXMYPT"
      },
      "source": [
        "### Gating as a Solution to a Vanilla RNN's Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrwpJiPFMlQh"
      },
      "source": [
        "## Example: A Character RNN for Generating Surnames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUsaDrtBMpON"
      },
      "source": [
        "### The SurnameDataset Class\r\n",
        "\r\n",
        "*Example 7-1. The `SurnameDataset.__getitem__()` method for a sequence prediction task*\r\n",
        "\r\n",
        "```\r\n",
        "class SurnameDataset(Dataset):\r\n",
        "    @classmethod\r\n",
        "    def load_dataset_and_make_vectorizer(cls, surname_csv):\r\n",
        "        \"\"\"Load dataset and make a vectorizer from scratch\r\n",
        "\r\n",
        "        Args:\r\n",
        "            surname_csv (str): location of the dataset\r\n",
        "        Returns:\r\n",
        "            an instance of SurnameDataset\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        surname_df = pd.read_csv(surname_csv)\r\n",
        "        return cls(surname_df, SurnameVectorizer.from_dataframe(surname_df))\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\r\n",
        "\r\n",
        "        Args:\r\n",
        "            index (int): the index to the data point\r\n",
        "        Returns:\r\n",
        "            a dictionary holding the data point: (x_data, y_target, class_index)\r\n",
        "        \"\"\"\r\n",
        "        row = self._target_df.iloc[index]\r\n",
        "\r\n",
        "        from_vector, to_vector = \\\r\n",
        "            self._vectorizer.vectorize(row.surname, self._max_seq_length)\r\n",
        "\r\n",
        "        nationality_index = \\\r\n",
        "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\r\n",
        "\r\n",
        "        return {'x_data': from_vector,\r\n",
        "                'y_target': to_vector,\r\n",
        "                'class_index': nationality_index}\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6EBgnMcNvd-"
      },
      "source": [
        "### The Vectorization Data Structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbjBOZecNyal"
      },
      "source": [
        "#### SurnameVectorizer and END-OF-SEQUENCE\r\n",
        "\r\n",
        "*Example 7-2. The code for `SurnameVectorizer.vectorize()` in a sequence prediction task*\r\n",
        "\r\n",
        "```\r\n",
        "class SurnameVectorizer(object):\r\n",
        "    \"\"\"The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\r\n",
        "\r\n",
        "    def vectorizer(self, surname, vector_length=-1):\r\n",
        "        \"\"\"Vectorizer a surname into a vector of observations and targets\r\n",
        "\r\n",
        "        Args:\r\n",
        "            surname (str): the surname to be vectorized\r\n",
        "            vector_length (int): an argument for forcing the length of index vector\r\n",
        "        Returns:\r\n",
        "            a tuple: (from_vector, to_vector)\r\n",
        "                from_vector (numpy.ndarray): the observation vector\r\n",
        "                to_vector (numpy.ndarray): the target prediction vector\r\n",
        "        \"\"\"\r\n",
        "        indices = [self.char_vocab.begin_seq_index]\r\n",
        "        indices.extend(self.char_vocab.lookup_token(token) for token in surname)\r\n",
        "        indices.append(self.char_vocab.end_seq_index)\r\n",
        "\r\n",
        "        if vector_length < 0:\r\n",
        "            vector_length = len(indices) -1\r\n",
        "\r\n",
        "        from_vector = np.zeros(vector_length, dtype=np.int64)\r\n",
        "        from_indices = indices[:-1]\r\n",
        "        from_vector[:len(from_indices)] = from_indices\r\n",
        "        from_vector[len(from_indices):] = self.char_vocab.mask_index\r\n",
        "\r\n",
        "        to_vector = np.emtpy(vector_length, dtype=np.int64)\r\n",
        "        to_indices = indices[1:]\r\n",
        "        to_vector[:len(to_indices)] = to_indices\r\n",
        "        to_vector[len(to_indices):] = self.char_vocab.mask_index  \r\n",
        "\r\n",
        "        return from_vector, to_vector\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_dataframe(cls, surname_df):\r\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\r\n",
        "\r\n",
        "        Args:\r\n",
        "            surname_df (pandas.DataFrame): the surname dataset\r\n",
        "        Returns:\r\n",
        "            an instance of the SurnameVectorizer\r\n",
        "        \"\"\"\r\n",
        "        char_vocab = SequenceVocabulary()\r\n",
        "        nationality_vocab = Vocabulary()\r\n",
        "\r\n",
        "        for index, row in surname_df.itterrows():\r\n",
        "            for char in row.surname:\r\n",
        "                char_vocab.add_token(char)\r\n",
        "            nationality_vocab.add_token(row.nationality)\r\n",
        "\r\n",
        "        return cls(char_vocab, nationality_vocab)     \r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U21nd47PqCI"
      },
      "source": [
        "### From the ElmanRNN to the GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bHsRvGePs-Z"
      },
      "source": [
        "### Model 1: The Uncondioned SurnameGenerationModel\r\n",
        "\r\n",
        "*Example 7-3. The unconditioned surname generation model*\r\n",
        "\r\n",
        "```\r\n",
        "class SurnameGenerationModel(nn.Module):\r\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size,\r\n",
        "                 batch_first=True, padding_idx=0, dropout_p=0.5):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            char_embedding_size (int): the size of the character embeddings\r\n",
        "            char_vocab_size (int): the number of characters to embed\r\n",
        "            rnn_hidden_size (int): the size of the RNN's hidden state\r\n",
        "            batch_first (bool): informs whether the input tnesors will\r\n",
        "                have batch or the sequence on the 0th dimension\r\n",
        "            padding_idx (int): the index for the tensor padding;\r\n",
        "                see torch.nn.Embedding\r\n",
        "            dropout_p (float): the probability of zeroing activations using the dropout method\r\n",
        "        \"\"\"\r\n",
        "        super(SurnameGenerationModel, self).__init__()\r\n",
        "\r\n",
        "        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\r\n",
        "                                     embedding_dim=char_embedding_size,\r\n",
        "                                     padding_idx=padding_idx)\r\n",
        "        self.rnn = nn.GRU(input_size=char_embedding_size,\r\n",
        "                          hidden_size=rnn_hidden_size,\r\n",
        "                          batch_first=batch_first)\r\n",
        "        self.fc = nn.Linear(in_features=rnn_hidden_size,\r\n",
        "                            out_features=char_vocab_size)\r\n",
        "        self._dropout_p = dropout_p\r\n",
        "\r\n",
        "    def forward(self, x_in, apply_softmax=False):\r\n",
        "        \"\"\"The forward pass of the model\r\n",
        "\r\n",
        "        Args:\r\n",
        "            x_in (torch.Tensor): an input data tensor\r\n",
        "                x_in.shape should be (batch, input_dim)\r\n",
        "            apply_softmax (bool): a flag for the softmax activation\r\n",
        "                should be False during training\r\n",
        "        Returns:\r\n",
        "            the resulting tensor\r\n",
        "                tensor.shape should be (batch, output_dim)\r\n",
        "        \"\"\"\r\n",
        "        x_embedded = self.char_emb(x_in)\r\n",
        "\r\n",
        "        y_out, _ = self.rnn(x_embedded)\r\n",
        "\r\n",
        "        batch_size, seq_size, feat_size = y_out.shape\r\n",
        "        y_out = y_out.continguous().view(batch_size * seq_size, feat_size)\r\n",
        "\r\n",
        "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\r\n",
        "\r\n",
        "        if apply_softmax:\r\n",
        "            y_out = F.softmax(y_out, dim=1)\r\n",
        "\r\n",
        "        new_feat_size = y_out.shape[-1]\r\n",
        "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\r\n",
        "\r\n",
        "        return y_out\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxu99D5CRpJM"
      },
      "source": [
        "### Model 2: The Conditioned SurnameGenerationModel\r\n",
        "\r\n",
        "*Example 7-4. The conditioned surname generation model*\r\n",
        "\r\n",
        "```\r\n",
        "class SurnameGenerationModel(nn.Module):\r\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, num_nationalities,\r\n",
        "                 rnn_hidden_size, batch_first=True, padding_idx=0, dropout_p=0.5):\r\n",
        "        # ...\r\n",
        "        self.nation_embedding = nn.Embedding(embedding_dim=rnn_hidden_size,\r\n",
        "                                             num_embeddings=num_nationalities)\r\n",
        "\r\n",
        "    def forward(self, x_In, nationality_index, apply_softmax=False):\r\n",
        "        # ...\r\n",
        "        x_embedded = self.char_embedding(x_in)\r\n",
        "        # hidden_size: (num_layers * num_directions, batch_size, rnn_hidden_size)\r\n",
        "        nationality_embedded = self.nation_emb(nationality_index).unsqueeze(0)\r\n",
        "        y_out, _ = self.rnn(x_embedded, nationality_embedded)\r\n",
        "        # ...                                             \r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPamdbS0Sjg0"
      },
      "source": [
        "### The Training Routine and Results\r\n",
        "\r\n",
        "*Example 7-5. Handling three-dimensional tensors and sequence-wide loss computations*\r\n",
        "\r\n",
        "```\r\n",
        "def normalize_sizes(y_pred, y_true):\r\n",
        "    \"\"\"Normalize tensor sizes\r\n",
        "\r\n",
        "    Args:\r\n",
        "        y_pred (torch.Tensor): the output of the model\r\n",
        "            if a 3-d tensor, reshapes to a matrix\r\n",
        "        y_true (torch.Tensor): the target predictions\r\n",
        "            if a matrix, reshapes to be a vector\r\n",
        "    \"\"\"\r\n",
        "    if len(y_pred.size()) == 3:\r\n",
        "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\r\n",
        "    if len(y_true.size()) == 2:\r\n",
        "        y_true = y_true.contiguous().view(-1)\r\n",
        "    return y_pred, y_true\r\n",
        "\r\n",
        "def sequence_loss(y_pred, y_true, mask_index):\r\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\r\n",
        "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)\r\n",
        "```\r\n",
        "\r\n",
        "*Example 7-6. Hyperparameters for surname generation*\r\n",
        "\r\n",
        "```\r\n",
        "args = Namespace(\r\n",
        "    # Data and path information\r\n",
        "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\r\n",
        "    vectorizer_file=\"vectorizer.json\",\r\n",
        "    model_state_file=\"model.pth\",\r\n",
        "    save_dir=\"model_storage/ch7/model1_unconditioned_surname_generation\",\r\n",
        "    # or: save_dir=\"model_storage/ch7/model2_conditioned_surname_generation\",\r\n",
        "    # Model hyperparameters\r\n",
        "    char_embedding_size=32,\r\n",
        "    rnn_hidden_size=32,\r\n",
        "    # Training hyperparameters\r\n",
        "    seed=1337,\r\n",
        "    learning_rate=0.001,\r\n",
        "    batch_size=128,\r\n",
        "    num_epochs=100,\r\n",
        "    early_stopping_criteria=5,\r\n",
        "    # Runtime options omitted\r\n",
        ")    \r\n",
        "```\r\n",
        "\r\n",
        "*Example 7-7. Sampling from the unconditioned generation model*\r\n",
        "\r\n",
        "```\r\n",
        "def sample_from_model(model, vectorizer, num_samples=1, sample_size=20, \r\n",
        "                      temperature=1.0):\r\n",
        "    \"\"\"Sampel a sequence of indices from the model\r\n",
        "\r\n",
        "    Args:\r\n",
        "        model (SurnameGenerationModel): the trained model\r\n",
        "        vectorizer (SurnameVectorizer): the corresponding vectorizer\r\n",
        "        num_samples (int): the number of samples\r\n",
        "        sample_size (int): the max length of the samples\r\n",
        "        temperature (float): accentuates or flattens the distribution\r\n",
        "            0.0 < temperature < 1.0 will make it peakier\r\n",
        "            temperature > 1.0 will make it more uniform\r\n",
        "    Returns:\r\n",
        "        indices (torch.Tensor): the matrix of indices\r\n",
        "        shape = (num_samples, sample_size)\r\n",
        "    \"\"\"\r\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index \r\n",
        "                       for _ in range(num_samples)]\r\n",
        "    being_seq_index = torch.tensor(begin_seq_index,\r\n",
        "                                   dtype=torch.int64).unsqueeze(dim=1)\r\n",
        "    indices = [begin_seq_index]\r\n",
        "    h_t = None\r\n",
        "\r\n",
        "    for time_step in range(sample_size):\r\n",
        "        x_t indices[time_step]\r\n",
        "        x_emb_t = model.char_emb(x_t)\r\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\r\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\r\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1))\r\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\r\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\r\n",
        "    return indices                                                                       \r\n",
        "```\r\n",
        "\r\n",
        "*Example 7-8. Mapping sampled indices to surname strings*\r\n",
        "\r\n",
        "```\r\n",
        "def decode_samples(sampled_indices, vectorizer):\r\n",
        "    \"\"\"Transform indices into the string form of a surname\r\n",
        "\r\n",
        "    Args:\r\n",
        "        sampled_indices (torch.Tensor): the indices from `sample_from_model`\r\n",
        "        vectorizer (SurnameVectorizer): the corresponding vectorizer\r\n",
        "    \"\"\"\r\n",
        "    decoded_surnames = []\r\n",
        "    vocab = vectorizer.char_vocab\r\n",
        "\r\n",
        "    for sample_index in range(sampled_indices.shape[0]):\r\n",
        "        surname = \"\"\r\n",
        "        for time_step in range(sampled_indices.shape[1]):\r\n",
        "            sample_item = sampled_indices[sample_index, time_step].item()\r\n",
        "            if sample_item == vocab.begin_seq_index:\r\n",
        "                continue\r\n",
        "            elif sample_item == vocab.end_seq_index:\r\n",
        "                break\r\n",
        "            else:\r\n",
        "                surname += vocab.lookup_index(sample_item)\r\n",
        "        decoded_surnames.append(surname)\r\n",
        "    return decoded_surnames\r\n",
        "```\r\n",
        "\r\n",
        "*Example 7-9. Sampling from the unconditioned model*\r\n",
        "\r\n",
        "```\r\n",
        "samples = sample_from_model(unconditioned_model, vectorizer, \r\n",
        "                              num_samples=10)\r\n",
        "\r\n",
        "decode_samples(samples, vectorizer)                              \r\n",
        "```\r\n",
        "\r\n",
        "*Example 7-10. Sampling from a sequence model*\r\n",
        "\r\n",
        "```\r\n",
        "def sample_from_model(model, vectorizer, nationalities, sample_size=20,\r\n",
        "                      temperature=1.0):\r\n",
        "    \"\"\"Sample a sequence of indices from the model\r\n",
        "\r\n",
        "    Args:\r\n",
        "        model (SurnameGenerationModel): the trained model\r\n",
        "        vectorizer (SurnameVectorizer): the corresponding vectorizer\r\n",
        "        nationalities (list): a list of integers representing nationalities\r\n",
        "        sample_size (int): the max length of the samples\r\n",
        "        temperature (float): accentuates or flattens the dsitribution\r\n",
        "            0.0 < temperature < 1.0 will make it peakier\r\n",
        "            temperature > 1.0 will make it more uniform\r\n",
        "    Returns:\r\n",
        "        indices (torch.Tensor): the matrix of indices\r\n",
        "        shape = (num_samples, sample_size)\r\n",
        "    \"\"\"\r\n",
        "    num_samples = len(nationalities)\r\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index\r\n",
        "                       for _ in range(num_samples)]\r\n",
        "    begin_seq_index = torch.tensor(being_seq_index,\r\n",
        "                                   dtype=torch.int64).unsqeeuze(dim=1)\r\n",
        "    indices = [begin_seq_index]\r\n",
        "    nationality_indices = torch.tensor(nationalities,\r\n",
        "                                       dtype=torch.int64).unsqueeze(dim=0)\r\n",
        "    h_t = model.nation_emb(nationlity_indices)\r\n",
        "\r\n",
        "    for time_step in range(sample_size):\r\n",
        "        x_t = indices[time_step]\r\n",
        "        x_emb_t = model.char_emb(x_t)\r\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\r\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\r\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\r\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\r\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\r\n",
        "    return indices                                                                      \r\n",
        "```\r\n",
        "\r\n",
        "*Example 7-11. Sampling from the conditioned SurnameGenerationModel*\r\n",
        "\r\n",
        "```\r\n",
        "for index in range(len(vectorizer.nationality_vocab)):\r\n",
        "    nationality = vectorizer.nationality_vocab.lookup_index(index)\r\n",
        "    \r\n",
        "    print(\"Sampled for {}: \".format(nationality))\r\n",
        "\r\n",
        "    sampled_indices = sample_from_model(model=conditioned_model,\r\n",
        "                                        vectorizer=vectorizer,\r\n",
        "                                        nationalities=[index] * 3,\r\n",
        "                                        temperature=0.7)\r\n",
        "    for sampled_surname in decode_samples(sampled_indices,\r\n",
        "                                          vectorizer):\r\n",
        "        print(\"- \" + sampled_surname)                                                                                  \r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nujtYL6emQ2r"
      },
      "source": [
        "## Tips and Tricks for Training Sequence Models\r\n",
        "\r\n",
        "*Example 7-12. Applying gradient clipping in PyTorch*\r\n",
        "\r\n",
        "```\r\n",
        "# define you sequence model\r\n",
        "model = ...\r\n",
        "# define loss function\r\n",
        "loss_function = ...\r\n",
        "\r\n",
        "# training loop\r\n",
        "for _ in ...\"\r\n",
        "    ...\r\n",
        "    model.zero_grad()\r\n",
        "    output, hidden = model(data, hidden)\r\n",
        "    loss = loss_function(output, targets)\r\n",
        "    loss.backward()\r\n",
        "    torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)\r\n",
        "    ...\r\n",
        "```\r\n"
      ]
    }
  ]
}