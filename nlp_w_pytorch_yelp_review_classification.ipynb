{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_w_pytorch_yelp_review_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOzzueP66GFK/EQDKbMHJzx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64edebe1d1ab4d698d159981bc21ea60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b4bba41526394b41b940816019d250f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2b5c976323649c5b4ac9e63e210e8d5",
              "IPY_MODEL_05b0188bc77c414d95fc82e28e1cbf75"
            ]
          }
        },
        "b4bba41526394b41b940816019d250f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2b5c976323649c5b4ac9e63e210e8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1785593648f94b26a26a2fe186c9ba2b",
            "_dom_classes": [],
            "description": "training routine: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eeaaf511fad24e599d7f72a4e9acf6ce"
          }
        },
        "05b0188bc77c414d95fc82e28e1cbf75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14e85bff2fbb4653b933ecc685266bbb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 199/? [23:25&lt;00:00,  6.89s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4463facaf2994d3fad47b8ca345f654f"
          }
        },
        "1785593648f94b26a26a2fe186c9ba2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eeaaf511fad24e599d7f72a4e9acf6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14e85bff2fbb4653b933ecc685266bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4463facaf2994d3fad47b8ca345f654f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25bce0565f0348d6a12bd05899481063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_203e2e0c854f401cb4c477532298d7d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3682a78f4d104e47bc4e86c1cb53476b",
              "IPY_MODEL_ea3db6c704014e9ab6ae55dae1ea0145"
            ]
          }
        },
        "203e2e0c854f401cb4c477532298d7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3682a78f4d104e47bc4e86c1cb53476b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4497c7c60b6e488098ebc6dd4e740953",
            "_dom_classes": [],
            "description": "split=train: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 305,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf5c0ecfe8124bcf9a2cba4cf3243815"
          }
        },
        "ea3db6c704014e9ab6ae55dae1ea0145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1639060de6dd44f8a0df5e7f08162d83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 305/306 [23:23&lt;00:10, 10.32s/it, acc=95.5, epoch=99, loss=0.132]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f447a5ba999f415cac77629adc478b53"
          }
        },
        "4497c7c60b6e488098ebc6dd4e740953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf5c0ecfe8124bcf9a2cba4cf3243815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1639060de6dd44f8a0df5e7f08162d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f447a5ba999f415cac77629adc478b53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cbc9f5e15724f899ab3e3e9a7ea2248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f8cc4aaa521b4fceb62dbd8d42097301",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7902ee34a3414756b0d09af2292dd8f6",
              "IPY_MODEL_7ac1a9aa07c9421babf3ad78f9a396c0"
            ]
          }
        },
        "f8cc4aaa521b4fceb62dbd8d42097301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7902ee34a3414756b0d09af2292dd8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_74b1909a2c4f4a6ca03a55b32d1a9131",
            "_dom_classes": [],
            "description": "split=val:  98%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 65,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 64,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d15d519269f74416b6167f7164f5a215"
          }
        },
        "7ac1a9aa07c9421babf3ad78f9a396c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_086dc0c9c75841229bfe0247da14a3cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 64/65 [23:25&lt;00:08,  8.60s/it, acc=92.2, epoch=99, loss=0.204]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_925ea60a0c1f40b49c390ebcdbf432f1"
          }
        },
        "74b1909a2c4f4a6ca03a55b32d1a9131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d15d519269f74416b6167f7164f5a215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "086dc0c9c75841229bfe0247da14a3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "925ea60a0c1f40b49c390ebcdbf432f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hookskl/nlp_w_pytorch/blob/main/nlp_w_pytorch_yelp_review_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXHnXDSzDlQB",
        "outputId": "6d43b85e-e7c5-4c82-da86-bdec40a7bdf0"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "# get python file shell script\r\n",
        "curl -o download.py https://raw.githubusercontent.com/hookskl/PyTorchNLPBook/master/data/download.py\r\n",
        "#! /bin/bash\r\n",
        "\r\n",
        "# For each file, add a download.py line\r\n",
        "# Any additional processing on the downloaded file\r\n",
        "\r\n",
        "HERE=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\r\n",
        "\r\n",
        "# Yelp Reviews dataset\r\n",
        "mkdir -p $HERE/yelp\r\n",
        "if [ ! -f $HERE/yelp/reviews_with_splits_lite.csv ]; then\r\n",
        "    python download.py 1Lmv4rsJiCWVs1nzs4ywA9YI-ADsTf6WB $HERE/yelp/reviews_with_splits_lite.csv # 1217\r\n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1572  100  1572    0     0  14555      0 --:--:-- --:--:-- --:--:-- 14555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYrA4CPwkaxP"
      },
      "source": [
        "\r\n",
        "from argparse import Namespace\r\n",
        "from collections import Counter\r\n",
        "import json\r\n",
        "import os\r\n",
        "import re\r\n",
        "import string\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIob_-Jwkr3S"
      },
      "source": [
        "class Vocabulary(object):\r\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\r\n",
        "            add_unk (bool): a flag that indicates whether to add the UNK token\r\n",
        "            unk_token (str): the UNK token to add into the Vocabulary\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        if token_to_idx is None:\r\n",
        "            token_to_idx = {}\r\n",
        "        self._token_to_idx = token_to_idx\r\n",
        "\r\n",
        "        self._idx_to_token = {idx: token \r\n",
        "                              for token, idx in self._token_to_idx.items()}\r\n",
        "        \r\n",
        "        self._add_unk = add_unk\r\n",
        "        self._unk_token = unk_token\r\n",
        "        \r\n",
        "        self.unk_index = -1\r\n",
        "        if add_unk:\r\n",
        "            self.unk_index = self.add_token(unk_token) \r\n",
        "        \r\n",
        "        \r\n",
        "    def to_serializable(self):\r\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\r\n",
        "        return {'token_to_idx': self._token_to_idx, \r\n",
        "                'add_unk': self._add_unk, \r\n",
        "                'unk_token': self._unk_token}\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_serializable(cls, contents):\r\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\r\n",
        "        return cls(**contents)\r\n",
        "\r\n",
        "    def add_token(self, token):\r\n",
        "        \"\"\"Update mapping dicts based on the token.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            token (str): the item to add into the Vocabulary\r\n",
        "        Returns:\r\n",
        "            index (int): the integer corresponding to the token\r\n",
        "        \"\"\"\r\n",
        "        if token in self._token_to_idx:\r\n",
        "            index = self._token_to_idx[token]\r\n",
        "        else:\r\n",
        "            index = len(self._token_to_idx)\r\n",
        "            self._token_to_idx[token] = index\r\n",
        "            self._idx_to_token[index] = token\r\n",
        "        return index\r\n",
        "    \r\n",
        "    def add_many(self, tokens):\r\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            tokens (list): a list of string tokens\r\n",
        "        Returns:\r\n",
        "            indices (list): a list of indices corresponding to the tokens\r\n",
        "        \"\"\"\r\n",
        "        return [self.add_token(token) for token in tokens]\r\n",
        "\r\n",
        "    def lookup_token(self, token):\r\n",
        "        \"\"\"Retrieve the index associated with the token \r\n",
        "          or the UNK index if token isn't present.\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            token (str): the token to look up \r\n",
        "        Returns:\r\n",
        "            index (int): the index corresponding to the token\r\n",
        "        Notes:\r\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \r\n",
        "              for the UNK functionality \r\n",
        "        \"\"\"\r\n",
        "        if self.unk_index >= 0:\r\n",
        "            return self._token_to_idx.get(token, self.unk_index)\r\n",
        "        else:\r\n",
        "            return self._token_to_idx[token]\r\n",
        "\r\n",
        "    def lookup_index(self, index):\r\n",
        "        \"\"\"Return the token associated with the index\r\n",
        "        \r\n",
        "        Args: \r\n",
        "            index (int): the index to look up\r\n",
        "        Returns:\r\n",
        "            token (str): the token corresponding to the index\r\n",
        "        Raises:\r\n",
        "            KeyError: if the index is not in the Vocabulary\r\n",
        "        \"\"\"\r\n",
        "        if index not in self._idx_to_token:\r\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\r\n",
        "        return self._idx_to_token[index]\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bgdpLhGIX6C"
      },
      "source": [
        "class ReviewVectorizer(object):\r\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\r\n",
        "    def __init__(self, review_vocab, rating_vocab):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            review_vocab (Vocabulary): maps words to integers\r\n",
        "            rating_vocab (Vocabulary): maps class labels to integers\r\n",
        "        \"\"\"\r\n",
        "        self.review_vocab = review_vocab\r\n",
        "        self.rating_vocab = rating_vocab\r\n",
        "\r\n",
        "    def vectorize(self, review):\r\n",
        "        \"\"\"Create a collapsed one-hit vector for the review\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            review (str): the review \r\n",
        "        Returns:\r\n",
        "            one_hot (np.ndarray): the collapsed one-hot encoding \r\n",
        "        \"\"\"\r\n",
        "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\r\n",
        "        \r\n",
        "        for token in review.split(\" \"):\r\n",
        "            if token not in string.punctuation:\r\n",
        "                one_hot[self.review_vocab.lookup_token(token)] = 1\r\n",
        "\r\n",
        "        return one_hot\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_dataframe(cls, review_df, cutoff=25):\r\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            review_df (pandas.DataFrame): the review dataset\r\n",
        "            cutoff (int): the parameter for frequency-based filtering\r\n",
        "        Returns:\r\n",
        "            an instance of the ReviewVectorizer\r\n",
        "        \"\"\"\r\n",
        "        review_vocab = Vocabulary(add_unk=True)\r\n",
        "        rating_vocab = Vocabulary(add_unk=False)\r\n",
        "        \r\n",
        "        # Add ratings\r\n",
        "        for rating in sorted(set(review_df.rating)):\r\n",
        "            rating_vocab.add_token(rating)\r\n",
        "\r\n",
        "        # Add top words if count > provided count\r\n",
        "        word_counts = Counter()\r\n",
        "        for review in review_df.review:\r\n",
        "            for word in review.split(\" \"):\r\n",
        "                if word not in string.punctuation:\r\n",
        "                    word_counts[word] += 1\r\n",
        "               \r\n",
        "        for word, count in word_counts.items():\r\n",
        "            if count > cutoff:\r\n",
        "                review_vocab.add_token(word)\r\n",
        "\r\n",
        "        return cls(review_vocab, rating_vocab)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def from_serializable(cls, contents):\r\n",
        "        \"\"\"Instantiate a ReviewVectorizer from a serializable dictionary\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            contents (dict): the serializable dictionary\r\n",
        "        Returns:\r\n",
        "            an instance of the ReviewVectorizer class\r\n",
        "        \"\"\"\r\n",
        "        review_vocab = Vocabulary.from_serializable(contents['review_vocab'])\r\n",
        "        rating_vocab =  Vocabulary.from_serializable(contents['rating_vocab'])\r\n",
        "\r\n",
        "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\r\n",
        "\r\n",
        "    def to_serializable(self):\r\n",
        "        \"\"\"Create the serializable dictionary for caching\r\n",
        "        \r\n",
        "        Returns:\r\n",
        "            contents (dict): the serializable dictionary\r\n",
        "        \"\"\"\r\n",
        "        return {'review_vocab': self.review_vocab.to_serializable(),\r\n",
        "                'rating_vocab': self.rating_vocab.to_serializable()}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0QUfzlVJb_M"
      },
      "source": [
        "class ReviewDataset(Dataset):\r\n",
        "    def __init__(self, review_df, vectorizer):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            review_df (pandas.DataFrame): the dataset\r\n",
        "            vectorizer (ReviewVectorizer): the vectorizer instantiated from dataset\r\n",
        "        \"\"\"\r\n",
        "        self.review_df = review_df\r\n",
        "        self._vectorizer = vectorizer\r\n",
        "\r\n",
        "        self.train_df = self.review_df[self.review_df.split=='train']\r\n",
        "        self.train_size = len(self.train_df)\r\n",
        "\r\n",
        "        self.val_df = self.review_df[self.review_df.split=='val']\r\n",
        "        self.validation_size = len(self.val_df)\r\n",
        "\r\n",
        "        self.test_df = self.review_df[self.review_df.split=='test']\r\n",
        "        self.test_size = len(self.test_df)\r\n",
        "\r\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\r\n",
        "                             'val': (self.val_df, self.validation_size),\r\n",
        "                             'test': (self.test_df, self.test_size)}\r\n",
        "        \r\n",
        "        self.set_split('train')  \r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def load_dataset_and_make_vectorizer(cls, review_csv):\r\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\r\n",
        "\r\n",
        "        Args:\r\n",
        "            review_csv (str): location of the dataset\r\n",
        "        Returns:\r\n",
        "            an instance of ReviewDataset\r\n",
        "        \"\"\"\r\n",
        "        review_df = pd.read_csv(review_csv)   \r\n",
        "        train_review_df = review_df[review_df.split=='train']\r\n",
        "        return cls(review_df, ReviewVectorizer.from_dataframe(train_review_df))\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def load_data_and_load_vectorizer(cls, review_csv, vectorizer_filepath):\r\n",
        "        \"\"\"Load dataset and the corresponding vectorizer\r\n",
        "        Used when the vectorizer has been cached for re-use\r\n",
        "\r\n",
        "        Args:\r\n",
        "            review_csv (str): location of the dataset  \r\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\r\n",
        "        Returns:\r\n",
        "            an instance of ReviewDataset\r\n",
        "        \"\"\"\r\n",
        "        review_df = pd.read_csv(review_csv)\r\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\r\n",
        "        return cls(review_df, vectorizer)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def load_vectorizer_only(vectorizer_filepath):\r\n",
        "        \"\"\"a static method for loading the vectorizer from file\r\n",
        "\r\n",
        "        Args:\r\n",
        "          vectorizer_filepath (str): the location of the serialized vectorizer\r\n",
        "        Returns:\r\n",
        "            an instance of ReviewVectorizer\r\n",
        "        \"\"\"\r\n",
        "        with open(vectorizer_filepath) as fp:\r\n",
        "            return ReviewVectorizer.from_serializable(json.load(fp))\r\n",
        "\r\n",
        "    def save_vectorizer(self, vectorizer_filepath):\r\n",
        "        \"\"\"saves the vectorizer to disk using json\r\n",
        "\r\n",
        "        Args:\r\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\r\n",
        "        \"\"\"\r\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\r\n",
        "              json.dump(self._vectorizer.to_serializable(), fp)\r\n",
        "\r\n",
        "    def get_vectorizer(self):\r\n",
        "        \"\"\"returns the vectorizer\"\"\"\r\n",
        "        return self._vectorizer\r\n",
        "    \r\n",
        "    def set_split(self, split=\"train\"):\r\n",
        "        \"\"\"selects the splits in the dataset using a column in the dataframe\r\n",
        "\r\n",
        "        Args:\r\n",
        "            split (str): one of \"train\", \"val\", or \"test\"\r\n",
        "        \"\"\"\r\n",
        "        self._target_split = split\r\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self._target_size\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"\"the primary entry point method for PyTorch datasets\r\n",
        "\r\n",
        "        Args:\r\n",
        "            index (int): the index to the data point\r\n",
        "        Returns:\r\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\r\n",
        "        \"\"\"\r\n",
        "        row = self._target_df.iloc[index]\r\n",
        "\r\n",
        "        review_vector = \\\r\n",
        "            self._vectorizer.vectorize(row.review)\r\n",
        "\r\n",
        "        rating_index = \\\r\n",
        "            self._vectorizer.rating_vocab.lookup_token(row.rating)\r\n",
        "\r\n",
        "        return {'x_data': review_vector,\r\n",
        "                'y_target': rating_index}\r\n",
        "\r\n",
        "    def get_num_batches(self, batch_size):\r\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\r\n",
        "\r\n",
        "        Args:\r\n",
        "            batch_size (int)\r\n",
        "        Returns:\r\n",
        "            number of batches in the dataset\r\n",
        "        \"\"\"\r\n",
        "        return len(self) // batch_size\r\n",
        "\r\n",
        "def generate_batches(dataset, batch_size, shuffle=True,\r\n",
        "                     drop_last=True, device=\"cpu\"):\r\n",
        "    \"\"\"\r\n",
        "    A generator function which wraps the PyTorch DataLoader. It will\r\n",
        "      ensure each tensor is on the right device location.\r\n",
        "    \"\"\"\r\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\r\n",
        "                            shuffle=shuffle, drop_last=drop_last)\r\n",
        "\r\n",
        "    for data_dict in dataloader:\r\n",
        "        out_data_dict = {}\r\n",
        "        for name, tensor in data_dict.items():\r\n",
        "            out_data_dict[name] = data_dict[name].to(device)\r\n",
        "        yield out_data_dict\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn82ph4beKvW"
      },
      "source": [
        "\r\n",
        "class ReviewClassifier(nn.Module):\r\n",
        "    \"\"\" a simple perceptron based classifier \"\"\"\r\n",
        "    def __init__(self, num_features):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            num_features (int): the size of the input feature vector\r\n",
        "        \"\"\"\r\n",
        "        super(ReviewClassifier, self).__init__()\r\n",
        "        self.fc1 = nn.Linear(in_features=num_features, \r\n",
        "                             out_features=1)\r\n",
        "\r\n",
        "    def forward(self, x_in, apply_sigmoid=False):\r\n",
        "        \"\"\"The forward pass of the classifier\r\n",
        "        \r\n",
        "        Args:\r\n",
        "            x_in (torch.Tensor): an input data tensor. \r\n",
        "                x_in.shape should be (batch, num_features)\r\n",
        "            apply_sigmoid (bool): a flag for the sigmoid activation\r\n",
        "                should be false if used with the Cross Entropy losses\r\n",
        "        Returns:\r\n",
        "            the resulting tensor. tensor.shape should be (batch,)\r\n",
        "        \"\"\"\r\n",
        "        y_out = self.fc1(x_in).squeeze()\r\n",
        "        if apply_sigmoid:\r\n",
        "            y_out = torch.sigmoid(y_out)\r\n",
        "        return y_out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBW6HVRJ_k7N"
      },
      "source": [
        "def make_train_state(args):\r\n",
        "    return {'stop_early': False,\r\n",
        "            'early_stopping_step': 0,\r\n",
        "            'early_stopping_best_val': 1e8,\r\n",
        "            'learning_rate': args.learning_rate,\r\n",
        "            'epoch_index': 0,\r\n",
        "            'train_loss': [],\r\n",
        "            'train_acc': [],\r\n",
        "            'val_loss': [],\r\n",
        "            'val_acc': [],\r\n",
        "            'test_loss': -1,\r\n",
        "            'test_acc': -1,\r\n",
        "            'model_filename': args.model_state_file}\r\n",
        "\r\n",
        "def update_train_state(args, model, train_state):\r\n",
        "    \"\"\"Handle the training state updates.\r\n",
        "\r\n",
        "    Components:\r\n",
        "      - Early Stopping: Prevent overfitting\r\n",
        "      - Model Checkpoint: Model is saved if the model is better\r\n",
        "\r\n",
        "      :param args: main arguments\r\n",
        "      :param model: model to train\r\n",
        "      :param train_state: a dictionary representing the training state values\r\n",
        "      :returns:\r\n",
        "          a new train_state\r\n",
        "    \"\"\"            \r\n",
        "\r\n",
        "    # Save one model at least\r\n",
        "    if train_state['epoch_index'] == 0:\r\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\r\n",
        "        train_state['stop_early'] = False\r\n",
        "\r\n",
        "    # Save model if performance improved\r\n",
        "    elif train_state['epoch_index'] >= 1:\r\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\r\n",
        "\r\n",
        "        # If loss worsened\r\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\r\n",
        "            # Update step\r\n",
        "            train_state['early_stopping_step'] += 1\r\n",
        "        # Loss decreased\r\n",
        "        else:\r\n",
        "            # Save the best model\r\n",
        "            if loss_t < train_state['early_stopping_best_val']:\r\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\r\n",
        "\r\n",
        "            # Reset early stopping step\r\n",
        "            train_state['early_stopping_step'] = 0\r\n",
        "\r\n",
        "        # Stop early?\r\n",
        "        train_state['stop_early'] = \\\r\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\r\n",
        "\r\n",
        "    return train_state\r\n",
        "\r\n",
        "def compute_accuracy(y_pred, y_target):\r\n",
        "    y_target = y_target.cpu()\r\n",
        "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()\r\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\r\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhxK1CT_CraB"
      },
      "source": [
        "def set_seed_everywhere(seed, cuda):\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    if cuda:\r\n",
        "        torch.cuda.manual_seed_all(seed)\r\n",
        "\r\n",
        "def handle_dirs(dirpath):\r\n",
        "    if not os.path.exists(dirpath):\r\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Syt7Vd3rCsCd",
        "outputId": "63bc95b6-9815-423c-eb53-d6c448e6b126"
      },
      "source": [
        "args = Namespace(\r\n",
        "    # Data and Path information\r\n",
        "    frequency_cutoff=25,\r\n",
        "    model_state_file='model.pth',\r\n",
        "    review_csv='yelp/reviews_with_splits_lite.csv',\r\n",
        "    # review_csv='data/yelp/reviews_with_splits_full.csv',\r\n",
        "    save_dir='model_storage/ch3/yelp/',\r\n",
        "    vectorizer_file='vectorizer.json',\r\n",
        "    # No Model hyper parameters\r\n",
        "    # Training hyper parameters\r\n",
        "    batch_size=128,\r\n",
        "    early_stopping_criteria=5,\r\n",
        "    learning_rate=0.001,\r\n",
        "    num_epochs=100,\r\n",
        "    seed=1337,\r\n",
        "    # Runtime options\r\n",
        "    catch_keyboard_interrupt=True,\r\n",
        "    cuda=True,\r\n",
        "    expand_filepaths_to_save_dir=True,\r\n",
        "    reload_from_files=False,\r\n",
        ")\r\n",
        "\r\n",
        "if args.expand_filepaths_to_save_dir:\r\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\r\n",
        "                                        args.vectorizer_file)\r\n",
        "\r\n",
        "    args.model_state_file = os.path.join(args.save_dir,\r\n",
        "                                         args.model_state_file)\r\n",
        "    \r\n",
        "    print(\"Expanded filepaths: \")\r\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\r\n",
        "    print(\"\\t{}\".format(args.model_state_file))\r\n",
        "    \r\n",
        "# Check CUDA\r\n",
        "if not torch.cuda.is_available():\r\n",
        "    args.cuda = False\r\n",
        "\r\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\r\n",
        "\r\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\r\n",
        "\r\n",
        "# Set seed for reproducibility\r\n",
        "set_seed_everywhere(args.seed, args.cuda)\r\n",
        "\r\n",
        "# handle dirs\r\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tmodel_storage/ch3/yelp/vectorizer.json\n",
            "\tmodel_storage/ch3/yelp/model.pth\n",
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pqCqtoZDMz6",
        "outputId": "7a7a96ee-072d-4abc-855f-f5f1420f9a91"
      },
      "source": [
        "if args.reload_from_files:\r\n",
        "    # training from a checkpoint\r\n",
        "    print(\"Loading dataset and vectorizer\")\r\n",
        "    dataset = ReviewDataset.load_dataset_and_load_vectorizer(args.review_csv,\r\n",
        "                                                            args.vectorizer_file)\r\n",
        "else:\r\n",
        "    print(\"Loading dataset and creating vectorizer\")\r\n",
        "    # create dataset and vectorizer\r\n",
        "    dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv)\r\n",
        "    dataset.save_vectorizer(args.vectorizer_file)    \r\n",
        "vectorizer = dataset.get_vectorizer()\r\n",
        "\r\n",
        "classifier = ReviewClassifier(num_features=len(vectorizer.review_vocab))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset and creating vectorizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "64edebe1d1ab4d698d159981bc21ea60",
            "b4bba41526394b41b940816019d250f5",
            "b2b5c976323649c5b4ac9e63e210e8d5",
            "05b0188bc77c414d95fc82e28e1cbf75",
            "1785593648f94b26a26a2fe186c9ba2b",
            "eeaaf511fad24e599d7f72a4e9acf6ce",
            "14e85bff2fbb4653b933ecc685266bbb",
            "4463facaf2994d3fad47b8ca345f654f",
            "25bce0565f0348d6a12bd05899481063",
            "203e2e0c854f401cb4c477532298d7d6",
            "3682a78f4d104e47bc4e86c1cb53476b",
            "ea3db6c704014e9ab6ae55dae1ea0145",
            "4497c7c60b6e488098ebc6dd4e740953",
            "bf5c0ecfe8124bcf9a2cba4cf3243815",
            "1639060de6dd44f8a0df5e7f08162d83",
            "f447a5ba999f415cac77629adc478b53",
            "1cbc9f5e15724f899ab3e3e9a7ea2248",
            "f8cc4aaa521b4fceb62dbd8d42097301",
            "7902ee34a3414756b0d09af2292dd8f6",
            "7ac1a9aa07c9421babf3ad78f9a396c0",
            "74b1909a2c4f4a6ca03a55b32d1a9131",
            "d15d519269f74416b6167f7164f5a215",
            "086dc0c9c75841229bfe0247da14a3cd",
            "925ea60a0c1f40b49c390ebcdbf432f1"
          ]
        },
        "id": "DN4Z7tlRDUAd",
        "outputId": "688e21e8-1819-4adc-bb54-baea453fbdf0"
      },
      "source": [
        "classifier = classifier.to(args.device)\r\n",
        "\r\n",
        "loss_func = nn.BCEWithLogitsLoss()\r\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\r\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\r\n",
        "                                                 mode='min', factor=0.5,\r\n",
        "                                                 patience=1)\r\n",
        "\r\n",
        "train_state = make_train_state(args)\r\n",
        "\r\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \r\n",
        "                          total=args.num_epochs,\r\n",
        "                          position=0)\r\n",
        "\r\n",
        "dataset.set_split('train')\r\n",
        "train_bar = tqdm_notebook(desc='split=train',\r\n",
        "                          total=dataset.get_num_batches(args.batch_size), \r\n",
        "                          position=1, \r\n",
        "                          leave=True)\r\n",
        "dataset.set_split('val')\r\n",
        "val_bar = tqdm_notebook(desc='split=val',\r\n",
        "                        total=dataset.get_num_batches(args.batch_size), \r\n",
        "                        position=1, \r\n",
        "                        leave=True)\r\n",
        "\r\n",
        "try:\r\n",
        "    for epoch_index in range(args.num_epochs):\r\n",
        "        train_state['epoch_index'] = epoch_index\r\n",
        "\r\n",
        "        # Iterate over training dataset\r\n",
        "\r\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\r\n",
        "        dataset.set_split('train')\r\n",
        "        batch_generator = generate_batches(dataset, \r\n",
        "                                           batch_size=args.batch_size, \r\n",
        "                                           device=args.device)\r\n",
        "        running_loss = 0.0\r\n",
        "        running_acc = 0.0\r\n",
        "        classifier.train()\r\n",
        "\r\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "            # the training routine is these 5 steps:\r\n",
        "\r\n",
        "            # --------------------------------------\r\n",
        "            # step 1. zero the gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # step 2. compute the output\r\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'].float())\r\n",
        "\r\n",
        "            # step 3. compute the loss\r\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'].float())\r\n",
        "            loss_t = loss.item()\r\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "            # step 4. use loss to produce gradients\r\n",
        "            loss.backward()\r\n",
        "\r\n",
        "            # step 5. use optimizer to take gradient step\r\n",
        "            optimizer.step()\r\n",
        "            # -----------------------------------------\r\n",
        "            # compute the accuracy\r\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\r\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "\r\n",
        "            # update bar\r\n",
        "            train_bar.set_postfix(loss=running_loss, \r\n",
        "                                  acc=running_acc, \r\n",
        "                                  epoch=epoch_index)\r\n",
        "            train_bar.update()\r\n",
        "\r\n",
        "        train_state['train_loss'].append(running_loss)\r\n",
        "        train_state['train_acc'].append(running_acc)\r\n",
        "\r\n",
        "        # Iterate over val dataset\r\n",
        "\r\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\r\n",
        "        dataset.set_split('val')\r\n",
        "        batch_generator = generate_batches(dataset, \r\n",
        "                                           batch_size=args.batch_size, \r\n",
        "                                           device=args.device)\r\n",
        "        running_loss = 0.\r\n",
        "        running_acc = 0.\r\n",
        "        classifier.eval()\r\n",
        "\r\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "\r\n",
        "            # compute the output\r\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'].float())\r\n",
        "\r\n",
        "            # step 3. compute the loss\r\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'].float())\r\n",
        "            loss_t = loss.item()\r\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "            # compute the accuracy\r\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\r\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "            \r\n",
        "            val_bar.set_postfix(loss=running_loss, \r\n",
        "                                acc=running_acc, \r\n",
        "                                epoch=epoch_index)\r\n",
        "            val_bar.update()\r\n",
        "\r\n",
        "        train_state['val_loss'].append(running_loss)\r\n",
        "        train_state['val_acc'].append(running_acc)\r\n",
        "\r\n",
        "        train_state = update_train_state(args=args, model=classifier,\r\n",
        "                                         train_state=train_state)\r\n",
        "\r\n",
        "        scheduler.step(train_state['val_loss'][-1])\r\n",
        "\r\n",
        "        train_bar.n = 0\r\n",
        "        val_bar.n = 0\r\n",
        "        epoch_bar.update()\r\n",
        "\r\n",
        "        if train_state['stop_early']:\r\n",
        "            break\r\n",
        "\r\n",
        "        train_bar.n = 0\r\n",
        "        val_bar.n = 0\r\n",
        "        epoch_bar.update()\r\n",
        "except KeyboardInterrupt:\r\n",
        "    print(\"Exiting loop\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64edebe1d1ab4d698d159981bc21ea60",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25bce0565f0348d6a12bd05899481063",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=train', max=306.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cbc9f5e15724f899ab3e3e9a7ea2248",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=val', max=65.0, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBNL-KDqOXai"
      },
      "source": [
        "\r\n",
        "# compute the loss & accuracy on the test set using the best available model\r\n",
        "\r\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\r\n",
        "classifier = classifier.to(args.device)\r\n",
        "\r\n",
        "dataset.set_split('test')\r\n",
        "batch_generator = generate_batches(dataset, \r\n",
        "                                   batch_size=args.batch_size, \r\n",
        "                                   device=args.device)\r\n",
        "running_loss = 0.\r\n",
        "running_acc = 0.\r\n",
        "classifier.eval()\r\n",
        "\r\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\r\n",
        "    # compute the output\r\n",
        "    y_pred = classifier(x_in=batch_dict['x_data'].float())\r\n",
        "\r\n",
        "    # compute the loss\r\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'].float())\r\n",
        "    loss_t = loss.item()\r\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\r\n",
        "\r\n",
        "    # compute the accuracy\r\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\r\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\r\n",
        "\r\n",
        "train_state['test_loss'] = running_loss\r\n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-IZ883JOhJS",
        "outputId": "ff1d7d50-5c41-411f-d8d3-a52dfe4ca738"
      },
      "source": [
        "print(\"Test loss: {:.3f}\".format(train_state['test_loss']))\r\n",
        "print(\"Test Accuracy: {:.2f}\".format(train_state['test_acc']))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.214\n",
            "Test Accuracy: 91.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzrsBbQ4PMF5"
      },
      "source": [
        "\r\n",
        "def preprocess_text(text):\r\n",
        "    text = text.lower()\r\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\r\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\r\n",
        "    return text\r\n",
        "\r\n",
        "def predict_rating(review, classifier, vectorizer, decision_threshold=0.5):\r\n",
        "    \"\"\"Predict the rating of a review\r\n",
        "    \r\n",
        "    Args:\r\n",
        "        review (str): the text of the review\r\n",
        "        classifier (ReviewClassifier): the trained model\r\n",
        "        vectorizer (ReviewVectorizer): the corresponding vectorizer\r\n",
        "        decision_threshold (float): The numerical boundary which separates the rating classes\r\n",
        "    \"\"\"\r\n",
        "    review = preprocess_text(review)\r\n",
        "    \r\n",
        "    vectorized_review = torch.tensor(vectorizer.vectorize(review))\r\n",
        "    result = classifier(vectorized_review.view(1, -1))\r\n",
        "    \r\n",
        "    probability_value = torch.sigmoid(result).item()\r\n",
        "    index = 1\r\n",
        "    if probability_value < decision_threshold:\r\n",
        "        index = 0\r\n",
        "\r\n",
        "    return vectorizer.rating_vocab.lookup_index(index)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVD3cIavPWHd",
        "outputId": "71aaad07-102b-4cb2-f43c-9e6355f51cda"
      },
      "source": [
        "test_review = \"this is a pretty awesome book\"\r\n",
        "\r\n",
        "classifier = classifier.cpu()\r\n",
        "prediction = predict_rating(test_review, classifier, vectorizer, decision_threshold=0.5)\r\n",
        "print(\"{} -> {}\".format(test_review, prediction))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is a pretty awesome book -> positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD0wk6ymPnJU",
        "outputId": "c9ffb990-857c-4917-847c-77e2c2a8f740"
      },
      "source": [
        "classifier.fc1.weight.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7326])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjWSO_WmPqBz",
        "outputId": "66c22fc2-5d29-47ec-a707-f6e7631cf854"
      },
      "source": [
        "# Sort weights\r\n",
        "fc1_weights = classifier.fc1.weight.detach()[0]\r\n",
        "_, indices = torch.sort(fc1_weights, dim=0, descending=True)\r\n",
        "indices = indices.numpy().tolist()\r\n",
        "\r\n",
        "# Top 20 words\r\n",
        "print(\"Influential words in Positive Reviews:\")\r\n",
        "print(\"--------------------------------------\")\r\n",
        "for i in range(20):\r\n",
        "    print(vectorizer.review_vocab.lookup_index(indices[i]))\r\n",
        "    \r\n",
        "print(\"====\\n\\n\\n\")\r\n",
        "\r\n",
        "# Top 20 negative words\r\n",
        "print(\"Influential words in Negative Reviews:\")\r\n",
        "print(\"--------------------------------------\")\r\n",
        "indices.reverse()\r\n",
        "for i in range(20):\r\n",
        "    print(vectorizer.review_vocab.lookup_index(indices[i]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Influential words in Positive Reviews:\n",
            "--------------------------------------\n",
            "delicious\n",
            "fantastic\n",
            "pleasantly\n",
            "amazing\n",
            "great\n",
            "vegas\n",
            "yum\n",
            "excellent\n",
            "ngreat\n",
            "perfect\n",
            "awesome\n",
            "yummy\n",
            "love\n",
            "bomb\n",
            "solid\n",
            "notch\n",
            "perfection\n",
            "deliciousness\n",
            "chinatown\n",
            "pleased\n",
            "====\n",
            "\n",
            "\n",
            "\n",
            "Influential words in Negative Reviews:\n",
            "--------------------------------------\n",
            "worst\n",
            "mediocre\n",
            "bland\n",
            "horrible\n",
            "meh\n",
            "awful\n",
            "rude\n",
            "terrible\n",
            "tasteless\n",
            "overpriced\n",
            "disgusting\n",
            "unacceptable\n",
            "slowest\n",
            "poorly\n",
            "nmaybe\n",
            "unfriendly\n",
            "disappointing\n",
            "downhill\n",
            "underwhelmed\n",
            "disappointment\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}